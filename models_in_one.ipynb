{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled47.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6x_ULFzcsxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_ser_mem_usage(ser):\n",
        "  col_type = ser.dtype\n",
        "  if col_type != object:\n",
        "      c_min = ser.min()\n",
        "      c_max = ser.max()\n",
        "      if str(col_type)[:3] == 'int':\n",
        "          if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "              ser = ser.astype(np.int8)\n",
        "          elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "              ser = ser.astype(np.int16)\n",
        "          elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "              ser = ser.astype(np.int32)\n",
        "          elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "              ser = ser.astype(np.int64)  \n",
        "      else:\n",
        "          if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "              ser = ser.astype(np.float16)\n",
        "          elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "              ser = ser.astype(np.float32)\n",
        "          else:\n",
        "              ser = ser.astype(np.float64)\n",
        "  else:\n",
        "      ser = ser.astype('category')\n",
        "\n",
        "def reduce_df_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        reduce_ser_mem_usage(df[col])\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0lDkIQ_sKls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_result(model, D_test, Y_test):\n",
        "  preds = model.predict(D_test)\n",
        "  best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "  print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
        "  print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK6ECi_bcsUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L8eoBtc9aYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = datasets.load_digits()\n",
        "X = pd.DataFrame(dataset.data)\n",
        "y = pd.Series(dataset.target)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB2AlncTYfZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_iters_search(params, D_train, D_valid, y_valid, eval_func, n_iters=10, maximize=True,max_worse_iters=1):\n",
        "  best_model = None\n",
        "  best_params = None\n",
        "\n",
        "  best_local_model = None\n",
        "  best_local_params = None\n",
        "\n",
        "  if maximize:\n",
        "    best_result = -np.inf\n",
        "  else:\n",
        "    best_result = np.inf\n",
        "\n",
        "  params_mass = []\n",
        "  params_loc_mass = []\n",
        "  no_better_result = 0\n",
        "  for i in range(n_iters):\n",
        "    no_better_result += 1\n",
        "    model = copy.deepcopy(best_local_model)\n",
        "    if maximize:\n",
        "      best_loc = -np.inf\n",
        "    else:\n",
        "      best_loc = np.inf\n",
        "\n",
        "    for param in params:\n",
        "      model2 = xgb.train(param, D_train, param['num_iter'], xgb_model=model)\n",
        "      y_pred = model2.predict(D_valid)\n",
        "      score = eval_func(y_valid, y_pred)\n",
        "      if maximize:\n",
        "        if score > best_loc:\n",
        "          best_loc = score\n",
        "          best_local_model = copy.deepcopy(model2)\n",
        "          best_local_params = param\n",
        "        if score > best_result:\n",
        "          best_result = score\n",
        "          best_model = copy.deepcopy(model2)\n",
        "          best_params = param\n",
        "          no_better_result = 0\n",
        "      else:\n",
        "        if score < best_loc:\n",
        "          best_loc = score\n",
        "          best_local_model = copy.deepcopy(model2)\n",
        "          best_local_params = param\n",
        "        if score < best_result:\n",
        "          best_result = score\n",
        "          best_model = copy.deepcopy(model2)\n",
        "          best_params = param\n",
        "          no_better_result = 0\n",
        "\n",
        "    print('loc', best_loc)\n",
        "    print('global', best_result)\n",
        "\n",
        "    params_loc_mass.append(best_local_params)\n",
        "\n",
        "    if no_better_result == 0:\n",
        "      params_mass = copy.deepcopy(params_loc_mass)\n",
        "      best_model = copy.deepcopy(best_local_model)\n",
        "    \n",
        "    if no_better_result >= max_worse_iters:\n",
        "      return best_model, params_mass\n",
        "\n",
        "  return best_model, params_mass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyLuUj59w1vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_iters(params_mass, D_train):\n",
        "  model = None\n",
        "  for param in params_mass:\n",
        "    model = xgb.train(param, D_train, param['num_iter'], xgb_model=model)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTVGd3fU6kUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = [\n",
        "    {\n",
        "    'eta': 0.35, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':1,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.4, \n",
        "    'max_depth': 4,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':1,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 5,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':1,\n",
        "    },\n",
        "\n",
        "    {\n",
        "    'eta': 0.35, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':5,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.4, \n",
        "    'max_depth': 4,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':5,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 5,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':5,\n",
        "    },\n",
        "\n",
        "    {\n",
        "    'eta': 0.35, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':10,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.4, \n",
        "    'max_depth': 4,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':10,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 5,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':10,\n",
        "    },\n",
        "\n",
        "    {\n",
        "    'eta': 0.35, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':20,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.4, \n",
        "    'max_depth': 4,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':20,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 5,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':20,\n",
        "    },\n",
        "\n",
        "    {\n",
        "    'eta': 0.35, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':50,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.4, \n",
        "    'max_depth': 4,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':50,\n",
        "    },\n",
        "    {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 5,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 10,\n",
        "    'num_iter':50,\n",
        "    },\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "706J3P1UdXDZ",
        "colab_type": "code",
        "outputId": "ca597e4a-7219-44d7-c648-1542cee4ad94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "reduce_df_mem_usage(X_train)\n",
        "reduce_ser_mem_usage(y_train)\n",
        "D_train = xgb.DMatrix(X_train.copy(), label=y_train.copy())\n",
        "D_test = xgb.DMatrix(X_test, label=y_test)\n",
        "D_valid = xgb.DMatrix(X_valid, label=y_valid)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 0.62 MB\n",
            "Memory usage after optimization is: 0.62 MB\n",
            "Decreased by 0.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI-8wbsq_iDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "eb2334b7-f130-4509-e969-f979d8cad756"
      },
      "source": [
        "for param in params:\n",
        "  model = xgb.train(param, D_train, param['num_iter'])\n",
        "  get_result(model, D_test, y_test)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.8260146227412781\n",
            "Recall = 0.8295082333125811\n",
            "Accuracy = 0.8333333333333334\n",
            "Precision = 0.8918397834050008\n",
            "Recall = 0.8933072080898169\n",
            "Accuracy = 0.8925925925925926\n",
            "Precision = 0.8936221229191841\n",
            "Recall = 0.8880620345837735\n",
            "Accuracy = 0.8888888888888888\n",
            "Precision = 0.9224397071226884\n",
            "Recall = 0.9258460999029022\n",
            "Accuracy = 0.9222222222222223\n",
            "Precision = 0.9331581262939957\n",
            "Recall = 0.9369179009396401\n",
            "Accuracy = 0.9333333333333333\n",
            "Precision = 0.9278197696023784\n",
            "Recall = 0.9326118808727506\n",
            "Accuracy = 0.9296296296296296\n",
            "Precision = 0.9526022293825893\n",
            "Recall = 0.9551485109093806\n",
            "Accuracy = 0.9518518518518518\n",
            "Precision = 0.9549577203156664\n",
            "Recall = 0.9593151775760471\n",
            "Accuracy = 0.9555555555555556\n",
            "Precision = 0.9355637565832471\n",
            "Recall = 0.9417419175027872\n",
            "Accuracy = 0.937037037037037\n",
            "Precision = 0.9553881674852439\n",
            "Recall = 0.9589946647555344\n",
            "Accuracy = 0.9555555555555556\n",
            "Precision = 0.9584253432724198\n",
            "Recall = 0.96217232043319\n",
            "Accuracy = 0.9592592592592593\n",
            "Precision = 0.9536183943770151\n",
            "Recall = 0.9551485109093806\n",
            "Accuracy = 0.9518518518518518\n",
            "Precision = 0.9585435768906534\n",
            "Recall = 0.9618518076126772\n",
            "Accuracy = 0.9592592592592593\n",
            "Precision = 0.9625891036382261\n",
            "Recall = 0.9650294632903329\n",
            "Accuracy = 0.9629629629629629\n",
            "Precision = 0.9533019621211152\n",
            "Recall = 0.9538389870998566\n",
            "Accuracy = 0.9518518518518518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlKc_BymxhIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_func = lambda x,y: precision_score(x, np.asarray([np.argmax(line) for line in y]), average='macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDn_2l5NaOJs",
        "colab_type": "code",
        "outputId": "2c236cd8-b75e-4ca2-b05a-363d7478f163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model, model_params = train_iters_search(params, D_train, D_valid, y_valid, eval_func, n_iters=1000, maximize=True,max_worse_iters=10)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loc 0.9769003570727708\n",
            "global 0.9769003570727708\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n",
            "loc 0.9782620946305158\n",
            "global 0.9782620946305158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbXeWX0Myhex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7a23f787-6a8c-4d5a-b0c0-90e632b7c1f9"
      },
      "source": [
        "model_params"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'eta': 0.35,\n",
              "  'max_depth': 3,\n",
              "  'num_class': 10,\n",
              "  'num_iter': 50,\n",
              "  'objective': 'multi:softprob'},\n",
              " {'eta': 0.35,\n",
              "  'max_depth': 3,\n",
              "  'num_class': 10,\n",
              "  'num_iter': 10,\n",
              "  'objective': 'multi:softprob'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqQQkQtw19G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "58170ef3-79fc-4c03-a296-7870de1890db"
      },
      "source": [
        "model = train_iters(model_params, D_train)\n",
        "get_result(model, D_test, y_test)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.9591388149858915\n",
            "Recall = 0.9618518076126772\n",
            "Accuracy = 0.9592592592592593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65D92CqG_96c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}